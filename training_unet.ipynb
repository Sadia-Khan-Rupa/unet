{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"training_unet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPejvcZttt1eP2jTCbZYBkG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUsLxa-pEfcO","executionInfo":{"status":"ok","timestamp":1617090421888,"user_tz":-360,"elapsed":35635,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}},"outputId":"26f679a6-3751-4dd9-9cd3-62d65e507a75"},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bj-TZmcaq3u_","executionInfo":{"status":"ok","timestamp":1617090434416,"user_tz":-360,"elapsed":9476,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}},"outputId":"04e27f15-9a59-46c9-c6f4-a280846ea2d1"},"source":["pip uninstall keras"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Uninstalling Keras-2.4.3:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/Keras-2.4.3.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/docs/*\n","    /usr/local/lib/python3.7/dist-packages/keras/*\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.7/dist-packages/docs/md_autogen.py\n","    /usr/local/lib/python3.7/dist-packages/docs/update_docs.py\n","Proceed (y/n)? y\n","  Successfully uninstalled Keras-2.4.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mA-MXRjqnKjm","executionInfo":{"status":"ok","timestamp":1617090473011,"user_tz":-360,"elapsed":31893,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}},"outputId":"6ef72594-912a-4209-f2b6-3a8dab9fb524"},"source":["pip uninstall tensorflow"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.4.1:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.7/dist-packages/tensorflow-2.4.1.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2thgfL_Znb3J","executionInfo":{"status":"ok","timestamp":1617090478514,"user_tz":-360,"elapsed":17324,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}},"outputId":"dd6e0155-3a61-4793-8aea-db6474403865"},"source":["pip install keras==2.0.6\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting keras==2.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/45/f69527dca07582dddce1e66921484e50802f4d15095a72c793e15723bf46/Keras-2.0.6.tar.gz (228kB)\n","\r\u001b[K     |█▍                              | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 15.5MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30kB 10.4MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 40kB 9.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 71kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 81kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 143kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 153kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 163kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 174kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 184kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 194kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 204kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 215kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 225kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 6.8MB/s \n","\u001b[?25hRequirement already satisfied: theano in /usr/local/lib/python3.7/dist-packages (from keras==2.0.6) (1.0.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.0.6) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras==2.0.6) (1.15.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from theano->keras==2.0.6) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from theano->keras==2.0.6) (1.19.5)\n","Building wheels for collected packages: keras\n","  Building wheel for keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras: filename=Keras-2.0.6-cp37-none-any.whl size=266418 sha256=c9fc6af851486ca7a787e0b1a1f05e5f70796b2d8a358230d7398a07e7753bb0\n","  Stored in directory: /root/.cache/pip/wheels/d1/70/83/9be5aef9c4c863ea21adacd0be83139b20d3d819401a2b07d3\n","Successfully built keras\n","\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n","\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.0.6 which is incompatible.\u001b[0m\n","Installing collected packages: keras\n","Successfully installed keras-2.0.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yc8_Lb2Uoyji","executionInfo":{"status":"ok","timestamp":1617090506221,"user_tz":-360,"elapsed":23998,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}},"outputId":"3ea7a5c2-da75-4d6c-8a58-afce61478b95"},"source":["pip install tensorflow==1.13.0rc1"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.13.0rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/80/18adfb46ba0a4044e9feaa0897ceae4673ac07d34deeb74490bc0d4e4987/tensorflow-1.13.0rc1-cp37-cp37m-manylinux1_x86_64.whl (92.7MB)\n","\u001b[K     |████████████████████████████████| 92.7MB 66kB/s \n","\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n","\u001b[K     |████████████████████████████████| 368kB 43.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (1.19.5)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (1.1.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (3.12.4)\n","Collecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (0.36.2)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (0.3.3)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (0.8.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (1.32.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (0.10.0)\n","Collecting tensorboard<1.13.0,>=1.12.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 52.8MB/s \n","\u001b[?25hCollecting mock>=2.0.0\n","  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.0rc1) (54.1.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.0rc1) (2.10.0)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.13.0rc1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.13.0rc1) (3.3.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.13.0rc1) (3.7.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.13.0rc1) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.13.0rc1) (3.7.4.3)\n","Installing collected packages: mock, tensorflow-estimator, keras-applications, tensorboard, tensorflow\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.12.2 tensorflow-1.13.0rc1 tensorflow-estimator-1.13.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RK2XWtIdGMBo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617090514737,"user_tz":-360,"elapsed":4045,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}},"outputId":"72bce216-b3d5-4a05-f8dd-c2a08748cb02"},"source":["import numpy as np\n","import tensorflow as tf\n","import keras\n","from keras.models import Model\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Cropping2D, ZeroPadding2D, Conv2DTranspose\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n","from keras import backend as K\n","import os\n","from skimage.transform import resize\n","from skimage.io import imsave\n","import matplotlib.pyplot as plt"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hbR6VwemGZIh","executionInfo":{"status":"ok","timestamp":1617090522058,"user_tz":-360,"elapsed":1204,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}}},"source":["working_path = 'gdrive/My Drive/luna/output/'\n","main_path = 'gdrive/My Drive/luna/'\n","unet_weight = 'gdrive/My Drive/luna/unet.hdf5'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"nt4FSDl4Dou5","executionInfo":{"status":"ok","timestamp":1617090525185,"user_tz":-360,"elapsed":583,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}}},"source":["K.set_image_data_format('channels_first')  # Theano dimension ordering in this code\n","\n","BATCH_SIZE=8\n","EPOCHS=5\n","img_rows = 512\n","img_cols = 512\n","\n","smooth = 1.\n"," "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHV9rTtsGl7V","executionInfo":{"status":"ok","timestamp":1617090531119,"user_tz":-360,"elapsed":1127,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}}},"source":["def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"F6RwOkDxHwqY","executionInfo":{"status":"ok","timestamp":1617090536789,"user_tz":-360,"elapsed":896,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}}},"source":["def dice_coef_np(y_true, y_pred):\n","    y_true_f = y_true.flatten()\n","    y_pred_f = y_pred.flatten()\n","    intersection = np.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"LGw4ZTc0HwSM","executionInfo":{"status":"ok","timestamp":1617090542747,"user_tz":-360,"elapsed":1373,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}}},"source":["def dice_coef_loss(y_true, y_pred):\n","    return 1 - dice_coef(y_true, y_pred)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"PHdmcdWAJtac","executionInfo":{"status":"ok","timestamp":1617090549472,"user_tz":-360,"elapsed":1550,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}}},"source":["def get_model():\n","\n","      inputs = Input((1, img_rows, img_cols))\n","\n","      conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","      conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","      pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","      conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n","      conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","      pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","      conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n","      conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","      pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","      conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n","      conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","      pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","      conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n","      conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n","\n","      up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=1)\n","      conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n","      conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n","\n","      up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=1)\n","      conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n","      conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n","\n","      up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=1)\n","      conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n","      conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n","\n","      up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=1)\n","      conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n","      conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n","      conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n","\n","      model = Model(inputs=inputs, outputs=conv10)\n","      print (model.summary())\n","      print(len(model.layers))\n","      #     model.compile(optimizer=Adam(lr=1.0e-5), loss=dice_coef_loss, metrics=[dice_coef])\n","      model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics = ['accuracy'])\n","      return model\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ncWhW2u2LfjH","executionInfo":{"status":"ok","timestamp":1617090556577,"user_tz":-360,"elapsed":861,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}}},"source":["def get_unet1():\n","    \n","      K.set_image_data_format('channels_first')  # Theano dimension ordering in this code\n","      inputs = Input((1, img_rows, img_cols))\n","\n","      conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","      conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","      pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","      conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n","      conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","      pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","      conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n","      conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","      pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","      conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n","      conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","      pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","      conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n","      conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n","\n","      up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=1)\n","      conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n","      conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n","\n","      up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=1)\n","      conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n","      conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n","\n","      up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=1)\n","      conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n","      conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n","\n","      up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=1)\n","      conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n","      conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n","\n","      conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n","\n","      model = Model(inputs=[inputs], outputs=[conv10])\n","      print(len(model.layers))\n","      print (model.summary())\n","      #model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n","      model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics = ['accuracy'])\n","\n","      return model"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hRdcSofnLqKQ","executionInfo":{"status":"ok","timestamp":1617090564876,"user_tz":-360,"elapsed":1035,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}}},"source":["def get_unet():\n","\n","      K.set_image_data_format('channels_first')  # Theano dimension ordering in this code\n","      inputs = Input((1, img_rows, img_cols))\n","\n","      conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","      conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","      pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","      conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n","      conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","      pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","      conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n","      conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","      pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","      conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n","      conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","      pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","      conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n","      conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n","\n","      up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=1)\n","      conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n","      conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n","\n","      up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=1)\n","      conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n","      conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n","\n","      up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=1)\n","      conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n","      conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n","\n","      up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=1)\n","      conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n","      conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n","\n","      conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n","\n","      model = Model(inputs=[inputs], outputs=[conv10])\n","      print (model.summary())\n","      #model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n","      model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics = ['accuracy'])\n","      print(len(model.layers))\n","      return model\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"NAWfjaoTLrn1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617100409830,"user_tz":-360,"elapsed":7480405,"user":{"displayName":"Sadia Khan Rupa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyZLY0FsLYa6NLoTPHkG4s8J3SLBEAwehk4HBJyQ=s64","userId":"16377139398760852246"}},"outputId":"2ef318ff-b096-49d3-c5a6-191bd618a50a"},"source":["def train_and_predict(use_existing):\n","    print('-' * 30)\n","    print('Loading and preprocessing train data...')\n","    print ('BATCH_SIZE : {}'.format(BATCH_SIZE))\n","    print ('EPOCHS : {}'.format(EPOCHS))\n","    imgs_train = np.load(main_path + \"trainImages.npy\").astype(np.float32)\n","    imgs_mask_train = np.load(main_path + \"trainMasks.npy\").astype(np.float32)\n","    \n","#     imgs_val = np.load(main_path + \"valImages.npy\").astype(np.float32)\n","#     imgs_mask_val = np.load(main_path + \"valMasks.npy\").astype(np.float32)\n","    \n","    imgs_test = np.load(main_path + \"testImages.npy\").astype(np.float32)\n","    imgs_mask_test_true = np.load(main_path + \"testMasks.npy\").astype(np.float32)\n","\n","    mean = np.mean(imgs_train)  # mean for data centering\n","    std = np.std(imgs_train)  # std for data normalization\n","\n","    imgs_train -= mean  # images should already be standardized, but just in case\n","    imgs_train /= std\n","\n","    print('-' * 30)\n","    print('Creating and compiling model...')\n","\n","    model = get_model()\n","    # Saving weights to unet.hdf5 at checkpoints\n","\n","    best_weight_path = 'gdrive/My Drive/luna/unet.hdf5'\n","    model_checkpoint = ModelCheckpoint(best_weight_path, monitor='val_loss', save_best_only=True)\n","    tb = TensorBoard(log_dir=\"../logs_281118\", batch_size=BATCH_SIZE)\n","\n","    best_weight_path = 'gdrive/My Drive/luna/unet.hdf5'.format(BATCH_SIZE)\n","    model_checkpoint = ModelCheckpoint(best_weight_path, monitor='val_loss', save_best_only=True)\n","    tb = TensorBoard(log_dir='gdrive/My Drive/luna/', batch_size=BATCH_SIZE)\n","\n","    # Set argument for call to train_and_predict to true at end of script\n","    if use_existing:\n","        print('loading weights...')\n","        model.load_weights(unet_weight)\n","\n","    print('-' * 30)\n","    print('Fitting model...')\n","\n","    model.fit(imgs_train, imgs_mask_train, \n","              validation_split=0.15,\n","              batch_size=BATCH_SIZE, \n","              epochs=EPOCHS, \n","              verbose=1, shuffle=True,\n","              callbacks=[model_checkpoint,tb])\n","\n","\n","    # loading best weights from training session\n","    print('-' * 30)\n","    print('Loading saved weights...')\n","\n","\n","    model.load_weights(unet_weight)\n","\n","    model.load_weights(best_weight_path)\n","\n","\n","    print('-' * 30)\n","    print('Predicting masks on test data...')\n","\n","    num_test = len(imgs_test)\n","    imgs_mask_test = np.ndarray([num_test, 1, 512, 512], dtype=np.float32)\n","    for i in range(num_test):\n","        imgs_mask_test[i] = model.predict([imgs_test[i:i + 1]], verbose=0)[0]\n","\n","    np.save('gdrive/My Drive/luna/masksTestPredictedAll.npy', imgs_mask_test)\n","    \n","#     print('-' * 30)\n","#     print('Calculate mean dice coeff...')\n","    \n","#     mean = 0.0\n","#     for i in range(num_test):\n","#         mean += dice_coef_np(imgs_mask_test_true[i, 0], imgs_mask_test[i, 0])\n","#     mean /= num_test\n","\n","    np.save('gdrive/My Drive/luna/masks_mask_test.npy', imgs_mask_test)\n","    \n","    print('-' * 30)\n","    print('Calculate mean dice coeff...')\n","    \n","    mean = 0.0\n","    for i in range(num_test):\n","        mean += dice_coef_np(imgs_mask_test_true[i, 0], imgs_mask_test[i, 0])\n","    mean /= num_test\n","\n","#     print(\"Mean Dice Coeff : \", mean)\n","\n","if __name__ == '__main__':\n","    train_and_predict(True)\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["------------------------------\n","Loading and preprocessing train data...\n","BATCH_SIZE : 8\n","EPOCHS : 5\n","------------------------------\n","Creating and compiling model...\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","____________________________________________________________________________________________________\n","Layer (type)                     Output Shape          Param #     Connected to                     \n","====================================================================================================\n","input_1 (InputLayer)             (None, 1, 512, 512)   0                                            \n","____________________________________________________________________________________________________\n","conv2d_1 (Conv2D)                (None, 32, 512, 512)  320         input_1[0][0]                    \n","____________________________________________________________________________________________________\n","conv2d_2 (Conv2D)                (None, 32, 512, 512)  9248        conv2d_1[0][0]                   \n","____________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)   (None, 32, 256, 256)  0           conv2d_2[0][0]                   \n","____________________________________________________________________________________________________\n","conv2d_3 (Conv2D)                (None, 64, 256, 256)  18496       max_pooling2d_1[0][0]            \n","____________________________________________________________________________________________________\n","conv2d_4 (Conv2D)                (None, 64, 256, 256)  36928       conv2d_3[0][0]                   \n","____________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)   (None, 64, 128, 128)  0           conv2d_4[0][0]                   \n","____________________________________________________________________________________________________\n","conv2d_5 (Conv2D)                (None, 128, 128, 128) 73856       max_pooling2d_2[0][0]            \n","____________________________________________________________________________________________________\n","conv2d_6 (Conv2D)                (None, 128, 128, 128) 147584      conv2d_5[0][0]                   \n","____________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)   (None, 128, 64, 64)   0           conv2d_6[0][0]                   \n","____________________________________________________________________________________________________\n","conv2d_7 (Conv2D)                (None, 256, 64, 64)   295168      max_pooling2d_3[0][0]            \n","____________________________________________________________________________________________________\n","conv2d_8 (Conv2D)                (None, 256, 64, 64)   590080      conv2d_7[0][0]                   \n","____________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)   (None, 256, 32, 32)   0           conv2d_8[0][0]                   \n","____________________________________________________________________________________________________\n","conv2d_9 (Conv2D)                (None, 512, 32, 32)   1180160     max_pooling2d_4[0][0]            \n","____________________________________________________________________________________________________\n","conv2d_10 (Conv2D)               (None, 512, 32, 32)   2359808     conv2d_9[0][0]                   \n","____________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)   (None, 512, 64, 64)   0           conv2d_10[0][0]                  \n","____________________________________________________________________________________________________\n","concatenate_1 (Concatenate)      (None, 768, 64, 64)   0           up_sampling2d_1[0][0]            \n","                                                                   conv2d_8[0][0]                   \n","____________________________________________________________________________________________________\n","conv2d_11 (Conv2D)               (None, 256, 64, 64)   1769728     concatenate_1[0][0]              \n","____________________________________________________________________________________________________\n","conv2d_12 (Conv2D)               (None, 256, 64, 64)   590080      conv2d_11[0][0]                  \n","____________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)   (None, 256, 128, 128) 0           conv2d_12[0][0]                  \n","____________________________________________________________________________________________________\n","concatenate_2 (Concatenate)      (None, 384, 128, 128) 0           up_sampling2d_2[0][0]            \n","                                                                   conv2d_6[0][0]                   \n","____________________________________________________________________________________________________\n","conv2d_13 (Conv2D)               (None, 128, 128, 128) 442496      concatenate_2[0][0]              \n","____________________________________________________________________________________________________\n","conv2d_14 (Conv2D)               (None, 128, 128, 128) 147584      conv2d_13[0][0]                  \n","____________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)   (None, 128, 256, 256) 0           conv2d_14[0][0]                  \n","____________________________________________________________________________________________________\n","concatenate_3 (Concatenate)      (None, 192, 256, 256) 0           up_sampling2d_3[0][0]            \n","                                                                   conv2d_4[0][0]                   \n","____________________________________________________________________________________________________\n","conv2d_15 (Conv2D)               (None, 64, 256, 256)  110656      concatenate_3[0][0]              \n","____________________________________________________________________________________________________\n","conv2d_16 (Conv2D)               (None, 64, 256, 256)  36928       conv2d_15[0][0]                  \n","____________________________________________________________________________________________________\n","up_sampling2d_4 (UpSampling2D)   (None, 64, 512, 512)  0           conv2d_16[0][0]                  \n","____________________________________________________________________________________________________\n","concatenate_4 (Concatenate)      (None, 96, 512, 512)  0           up_sampling2d_4[0][0]            \n","                                                                   conv2d_2[0][0]                   \n","____________________________________________________________________________________________________\n","conv2d_17 (Conv2D)               (None, 32, 512, 512)  27680       concatenate_4[0][0]              \n","____________________________________________________________________________________________________\n","conv2d_18 (Conv2D)               (None, 32, 512, 512)  9248        conv2d_17[0][0]                  \n","____________________________________________________________________________________________________\n","conv2d_19 (Conv2D)               (None, 1, 512, 512)   33          conv2d_18[0][0]                  \n","====================================================================================================\n","Total params: 7,846,081\n","Trainable params: 7,846,081\n","Non-trainable params: 0\n","____________________________________________________________________________________________________\n","None\n","32\n","loading weights...\n","------------------------------\n","Fitting model...\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 122 samples, validate on 22 samples\n","Epoch 1/5\n","122/122 [==============================] - 1918s - loss: 0.5424 - acc: 0.1877 - val_loss: 0.5185 - val_acc: 0.1846\n","Epoch 2/5\n","122/122 [==============================] - 1897s - loss: 0.5140 - acc: 0.1901 - val_loss: 0.5110 - val_acc: 0.1811\n","Epoch 3/5\n","122/122 [==============================] - 1886s - loss: 0.5066 - acc: 0.1908 - val_loss: 0.5070 - val_acc: 0.1825\n","Epoch 4/5\n","122/122 [==============================] - 1879s - loss: 0.5021 - acc: 0.1917 - val_loss: 0.5010 - val_acc: 0.1853\n","Epoch 5/5\n","122/122 [==============================] - 1894s - loss: 0.4977 - acc: 0.1923 - val_loss: 0.4981 - val_acc: 0.1843\n","------------------------------\n","Loading saved weights...\n","------------------------------\n","Predicting masks on test data...\n","------------------------------\n","Calculate mean dice coeff...\n"],"name":"stdout"}]}]}